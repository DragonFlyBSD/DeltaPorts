#!/usr/bin/env python3
"""
apply-patch: Apply AI-generated patches, sync to DPorts, rebuild, and optionally open PR.

Usage:
    apply-patch --bundle <path> [--dry-run] [--no-rebuild] [--no-pr]

Environment variables:
    BUNDLE_DIR              Path to evidence bundle (alternative to --bundle)
    SAFE_DELTAPORTS_DIR     Safe clone for patch operations (default varies by platform)
    VM_SSH_KEY              SSH key for VM access (default: ~/.go-synth/vm/id_ed25519)
    VM_SSH_PORT             SSH port (default: 2222)
    VM_SSH_HOST             SSH host (default: root@localhost)

Platform modes:
    DragonFlyBSD (native): All operations run locally, no SSH needed
    Linux (dev host):      Uses SSH to VM for sync and rebuild operations

Safety:
    - NEVER modifies the protected checkout (~/s/DeltaPorts or /build/synth/DeltaPorts)
    - Always creates a new branch (never pushes to master)
    - Rebuild gate: PR is only opened after successful dsynth rebuild
"""

import argparse
import json
import os
import platform
import re
import subprocess
import sys
from datetime import datetime, timezone
from pathlib import Path


# Detect platform
IS_DRAGONFLY = platform.system() == "DragonFly"

# Protected paths that must NEVER be modified
PROTECTED_PATHS = {
    Path.home() / "s" / "DeltaPorts",
    Path("/home/antonioh/s/DeltaPorts"),
    Path("/build/synth/DeltaPorts"),
}

# Platform-specific defaults
if IS_DRAGONFLY:
    DEFAULT_SAFE_CLONE = Path("/build/synth/DeltaPorts-ai-fix")
    DEFAULT_DPORTS_DIR = Path("/build/synth/DPorts")
    DEFAULT_DELTAPORTS_DIR = Path("/build/synth/DeltaPorts")
else:
    DEFAULT_SAFE_CLONE = Path.home() / "s" / "DeltaPorts-ai-fix"
    DEFAULT_DPORTS_DIR = None  # Not used on Linux (SSH to VM)
    DEFAULT_DELTAPORTS_DIR = None

DEFAULT_SSH_KEY = Path.home() / ".go-synth" / "vm" / "id_ed25519"
DEFAULT_SSH_PORT = "2222"
DEFAULT_SSH_HOST = "root@localhost"


def log(level: str, message: str):
    """Log with timestamp."""
    ts = datetime.now(timezone.utc).strftime("%Y-%m-%dT%H:%M:%SZ")
    print(f"{ts} {level:5} {message}", file=sys.stderr)


def run(cmd: list[str], cwd: str | Path | None = None, check: bool = True, capture: bool = False) -> subprocess.CompletedProcess:
    """Run a command, logging it first."""
    cmd_str = " ".join(str(c) for c in cmd)
    log("CMD", cmd_str[:100] + ("..." if len(cmd_str) > 100 else ""))
    
    kwargs = {"cwd": cwd, "check": check}
    if capture:
        kwargs["capture_output"] = True
        kwargs["text"] = True
    
    return subprocess.run(cmd, **kwargs)


def ssh_cmd(host: str, port: str, key: Path, remote_cmd: str, check: bool = False) -> subprocess.CompletedProcess:
    """Run a command on the VM via SSH."""
    cmd = [
        "ssh",
        "-i", str(key),
        "-p", port,
        "-o", "StrictHostKeyChecking=no",
        "-o", "UserKnownHostsFile=/dev/null",
        host,
        remote_cmd
    ]
    return run(cmd, capture=True, check=check)


def parse_meta(bundle_dir: Path) -> dict:
    """Parse meta.txt from bundle."""
    meta = {}
    meta_path = bundle_dir / "meta.txt"
    if meta_path.exists():
        for line in meta_path.read_text().splitlines():
            if "=" in line:
                key, _, value = line.partition("=")
                meta[key.strip()] = value.strip()
    return meta


def parse_triage(bundle_dir: Path) -> dict:
    """Parse triage.md for classification and confidence."""
    result = {"classification": "", "confidence": "", "root_cause": ""}
    triage_path = bundle_dir / "analysis" / "triage.md"
    
    if not triage_path.exists():
        return result
    
    content = triage_path.read_text()
    
    # Extract Classification
    match = re.search(r"^##\s*Classification\s*\n+([^\n#]+)", content, re.MULTILINE | re.IGNORECASE)
    if match:
        result["classification"] = match.group(1).strip().lower()
    
    # Extract Confidence
    match = re.search(r"^##\s*Confidence\s*\n+([^\n#]+)", content, re.MULTILINE | re.IGNORECASE)
    if match:
        result["confidence"] = match.group(1).strip().lower()
    
    # Extract Root Cause (first sentence)
    match = re.search(r"^##\s*Root Cause\s*\n+([^\n#]+)", content, re.MULTILINE | re.IGNORECASE)
    if match:
        result["root_cause"] = match.group(1).strip()[:100]
    
    return result


def generate_branch_name(origin: str, classification: str) -> str:
    """Generate branch name: ai-fix/<category>-<port>-<bugslug>."""
    # Sanitize origin (category/port -> category-port)
    origin_safe = origin.replace("/", "-").replace("_", "-")
    
    # Create bugslug from classification
    bugslug = classification.replace("_", "-").replace(" ", "-")[:20]
    
    # Ensure valid git branch name
    branch = f"ai-fix/{origin_safe}-{bugslug}"
    branch = re.sub(r"[^a-zA-Z0-9/_-]", "", branch)
    
    return branch


def is_protected_path(path: Path) -> bool:
    """Check if path is a protected checkout."""
    resolved = path.resolve()
    for protected in PROTECTED_PATHS:
        try:
            if resolved == protected.resolve():
                return True
        except (OSError, ValueError):
            pass
    return False


def ensure_safe_clone(safe_dir: Path, dry_run: bool) -> bool:
    """Ensure safe clone exists and is up-to-date."""
    if is_protected_path(safe_dir):
        log("ERROR", f"REFUSING to use protected path as safe clone: {safe_dir}")
        return False
    
    if not safe_dir.exists():
        log("INFO", f"Creating safe clone at {safe_dir}")
        if dry_run:
            log("INFO", "[dry-run] would clone repository")
            return True
        
        # Clone from origin (use HTTPS for broader compatibility)
        run(["git", "clone", "https://github.com/DragonFlyBSD/DeltaPorts.git", str(safe_dir)])
    
    # Fetch latest and reset to origin/master
    log("INFO", "Updating safe clone to latest origin/master")
    if not dry_run:
        run(["git", "fetch", "origin"], cwd=safe_dir)
        run(["git", "checkout", "master"], cwd=safe_dir)
        run(["git", "reset", "--hard", "origin/master"], cwd=safe_dir)
    
    return True


def apply_patch_to_clone(safe_dir: Path, patch_path: Path, branch: str, origin: str, 
                         classification: str, bundle_dir: Path, dry_run: bool) -> tuple[bool, str]:
    """
    Apply patch to safe clone and commit.
    Returns (success, commit_sha).
    """
    if dry_run:
        log("INFO", f"[dry-run] would create branch {branch}")
        log("INFO", f"[dry-run] would apply patch from {patch_path}")
        return True, "dry-run-sha"
    
    # Create branch (delete if exists from previous attempt)
    run(["git", "branch", "-D", branch], cwd=safe_dir, check=False)
    run(["git", "checkout", "-b", branch], cwd=safe_dir)
    
    # Apply patch
    # Use -V none to prevent backup files (portable across BSD/GNU patch)
    patch_content = patch_path.read_text()
    log("INFO", f"Applying patch ({len(patch_content)} bytes)")
    
    result = subprocess.run(
        ["patch", "-p1", "--forward", "-V", "none"],
        cwd=safe_dir,
        input=patch_content,
        text=True,
        capture_output=True
    )
    
    if result.returncode != 0:
        log("ERROR", f"Patch failed: {result.stderr}")
        return False, ""
    
    log("INFO", f"Patch output: {result.stdout}")
    
    # Clean up any .orig files that might have been created
    for orig_file in safe_dir.rglob("*.orig"):
        log("INFO", f"Removing backup file: {orig_file}")
        orig_file.unlink()
    
    # Stage all changes
    run(["git", "add", "-A"], cwd=safe_dir)
    
    # Check if there are changes to commit
    status = run(["git", "status", "--porcelain"], cwd=safe_dir, capture=True)
    if not status.stdout.strip():
        log("WARN", "No changes to commit after applying patch")
        return False, ""
    
    # Commit
    commit_msg = f"""fix({origin}): {classification}

AI-generated fix for DragonFlyBSD build failure.

Classification: {classification}
Evidence bundle: {bundle_dir}

Generated by agentic-dsynth-evidence-hooks workflow.
"""
    
    run(["git", "commit", "-m", commit_msg], cwd=safe_dir)
    
    # Get commit SHA
    result = run(["git", "rev-parse", "HEAD"], cwd=safe_dir, capture=True)
    commit_sha = result.stdout.strip()
    
    return True, commit_sha


def push_branch(safe_dir: Path, branch: str, dry_run: bool) -> bool:
    """Push branch to origin."""
    if dry_run:
        log("INFO", f"[dry-run] would push branch {branch}")
        return True
    
    result = run(["git", "push", "-u", "origin", branch], cwd=safe_dir, check=False)
    return result.returncode == 0


def local_sync_from_safe_clone(origin: str, safe_dir: Path, dry_run: bool) -> bool:
    """
    Local mode without push: Sync directly from the safe clone to DPorts.
    
    This is used for local testing when we don't want to push to remote.
    We copy the port directory from the safe clone directly to DPorts.
    """
    if dry_run:
        log("INFO", f"[dry-run] would sync {origin} from safe clone to DPorts")
        return True
    
    dports_dir = Path(os.environ.get("DPORTS_DIR", str(DEFAULT_DPORTS_DIR)))
    
    # Source: safe_dir/ports/<origin>
    # Dest: dports_dir/<origin>
    src_port = safe_dir / "ports" / origin
    dst_port = dports_dir / origin
    
    if not src_port.exists():
        log("ERROR", f"Port not found in safe clone: {src_port}")
        return False
    
    log("INFO", f"Syncing {origin} from {src_port} to {dst_port}")
    
    # Remove existing and copy fresh
    if dst_port.exists():
        import shutil
        shutil.rmtree(dst_port)
    
    import shutil
    shutil.copytree(src_port, dst_port)
    
    log("INFO", f"Synced {origin} to DPorts")
    return True


def local_fetch_and_sync(origin: str, branch: str, safe_dir: Path, dry_run: bool) -> bool:
    """
    Local mode (DragonFlyBSD): Fetch branch in main DeltaPorts and run sync1.sh.
    
    On DragonFly, we:
    1. Update /build/synth/DeltaPorts to the new branch
    2. Run sync1.sh to sync changes to /build/synth/DPorts
    """
    if dry_run:
        log("INFO", f"[dry-run] would fetch branch {branch} locally")
        log("INFO", f"[dry-run] would run sync1.sh {origin}")
        return True
    
    deltaports_dir = Path(os.environ.get("DELTAPORTS_DIR", str(DEFAULT_DELTAPORTS_DIR)))
    
    # Clean up any local changes first
    log("INFO", f"Cleaning up {deltaports_dir}")
    run(["git", "reset", "--hard", "HEAD"], cwd=deltaports_dir, check=False)
    run(["git", "clean", "-fd"], cwd=deltaports_dir, check=False)
    
    # Fetch the branch
    log("INFO", f"Fetching branch {branch}")
    result = run(["git", "fetch", "origin", f"{branch}:{branch}"], cwd=deltaports_dir, check=False, capture=True)
    if result.returncode != 0:
        log("ERROR", f"git fetch failed: {result.stderr}")
        return False
    
    # Checkout the branch
    result = run(["git", "checkout", branch], cwd=deltaports_dir, check=False, capture=True)
    if result.returncode != 0:
        log("ERROR", f"git checkout failed: {result.stderr}")
        return False
    log("INFO", f"Checked out branch {branch}")
    
    # Run sync1.sh
    sync_script = deltaports_dir / "scripts" / "generator" / "sync1.sh"
    if not sync_script.exists():
        log("ERROR", f"sync1.sh not found at {sync_script}")
        return False
    
    result = run([str(sync_script), origin], cwd=sync_script.parent, check=False, capture=True)
    if result.returncode != 0:
        log("ERROR", f"sync1.sh failed: {result.stderr}")
        return False
    log("INFO", f"sync1.sh output: {result.stdout[:500] if result.stdout else '(no output)'}")
    
    return True


def vm_fetch_and_sync(origin: str, branch: str, ssh_host: str, ssh_port: str, 
                      ssh_key: Path, dry_run: bool) -> bool:
    """SSH mode (Linux host): Fetch branch on VM and run sync1.sh."""
    if dry_run:
        log("INFO", f"[dry-run] would fetch branch {branch} on VM")
        log("INFO", f"[dry-run] would run sync1.sh {origin}")
        return True
    
    # Clean up any local changes on the VM first
    cmd = "cd /build/synth/DeltaPorts && git reset --hard HEAD && git clean -fd"
    result = ssh_cmd(ssh_host, ssh_port, ssh_key, cmd)
    if result.returncode != 0:
        log("WARN", f"VM cleanup had issues: {result.stderr}")
    
    # Fetch the branch (use refspec to create local tracking branch)
    cmd = f"cd /build/synth/DeltaPorts && git fetch origin {branch}:{branch} && git checkout {branch}"
    result = ssh_cmd(ssh_host, ssh_port, ssh_key, cmd)
    if result.returncode != 0:
        log("ERROR", f"VM fetch failed: {result.stderr}")
        return False
    log("INFO", f"VM fetch output: {result.stdout}")
    
    # Run sync1.sh
    cmd = f"cd /build/synth/DeltaPorts/scripts/generator && ./sync1.sh {origin}"
    result = ssh_cmd(ssh_host, ssh_port, ssh_key, cmd)
    if result.returncode != 0:
        log("ERROR", f"sync1.sh failed: {result.stderr}")
        return False
    log("INFO", f"sync1.sh output: {result.stdout}")
    
    return True


def local_rebuild(origin: str, dry_run: bool) -> tuple[bool, str]:
    """
    Local mode (DragonFlyBSD): Run dsynth rebuild.
    Returns (success, log_excerpt).
    """
    if dry_run:
        log("INFO", f"[dry-run] would run dsynth force {origin}")
        return True, "[dry-run]"
    
    # Force rebuild
    log("INFO", f"Running dsynth force {origin}")
    result = run(["dsynth", "force", origin], capture=True, check=False)
    log("INFO", f"dsynth output: {result.stdout[:500] if result.stdout else '(no output)'}")
    
    # Check if build succeeded by looking at the logs
    log_name = origin.replace("/", "___") + ".log"
    log_path = Path("/build/synth/logs") / log_name
    
    log_excerpt = ""
    if log_path.exists():
        try:
            log_excerpt = log_path.read_text()[-2000:]  # Last 2000 chars
        except OSError:
            pass
    
    # Check success list
    success_list = Path("/build/synth/logs/01_success_list.log")
    success = False
    if success_list.exists():
        try:
            success = origin in success_list.read_text()
        except OSError:
            pass
    
    # Also check if package was created
    if not success:
        pkg_name = origin.split("/")[-1]
        pkg_dir = Path("/build/synth/packages/All")
        if pkg_dir.exists():
            for pkg_file in pkg_dir.glob(f"{pkg_name}*"):
                log("INFO", f"Package created: {pkg_file}")
                success = True
                break
    
    return success, log_excerpt


def vm_rebuild(origin: str, ssh_host: str, ssh_port: str, ssh_key: Path, 
               dry_run: bool) -> tuple[bool, str]:
    """
    Run dsynth rebuild on VM.
    Returns (success, log_excerpt).
    """
    if dry_run:
        log("INFO", f"[dry-run] would run dsynth force {origin}")
        return True, "[dry-run]"
    
    # Force rebuild
    cmd = f"dsynth force {origin} 2>&1"
    result = ssh_cmd(ssh_host, ssh_port, ssh_key, cmd)
    log("INFO", f"dsynth output: {result.stdout[:500]}")
    
    # Check if build succeeded by looking at the logs
    log_name = origin.replace("/", "___") + ".log"
    cmd = f"tail -20 /build/synth/logs/{log_name} 2>/dev/null || echo 'LOG NOT FOUND'"
    log_result = ssh_cmd(ssh_host, ssh_port, ssh_key, cmd)
    log_excerpt = log_result.stdout
    
    # Check success list
    cmd = f"grep -q '{origin}' /build/synth/logs/01_success_list.log 2>/dev/null && echo SUCCESS || echo FAILED"
    check_result = ssh_cmd(ssh_host, ssh_port, ssh_key, cmd)
    
    success = "SUCCESS" in check_result.stdout
    
    # Also check if package was created
    pkg_name = origin.split("/")[-1]
    cmd = f"ls /build/synth/packages/All/{pkg_name}* 2>/dev/null | head -1"
    pkg_result = ssh_cmd(ssh_host, ssh_port, ssh_key, cmd)
    if pkg_result.stdout.strip():
        log("INFO", f"Package created: {pkg_result.stdout.strip()}")
        success = True
    
    return success, log_excerpt


def create_pr(safe_dir: Path, branch: str, origin: str, classification: str,
              confidence: str, root_cause: str, bundle_dir: Path, dry_run: bool) -> str | None:
    """
    Create PR using gh CLI.
    Returns PR URL or None.
    """
    if dry_run:
        log("INFO", "[dry-run] would create PR")
        return "https://github.com/example/pr/123"
    
    title = f"fix({origin}): {classification}"
    
    body = f"""## Summary
AI-assisted fix for `{origin}` build failure on DragonFlyBSD.

## Triage Analysis
- **Classification**: {classification}
- **Confidence**: {confidence}
- **Root Cause**: {root_cause}

## Rebuild Result
Build succeeded on DragonFlyBSD VM (dsynth force).

## Evidence
Bundle: `{bundle_dir}`

---
*This PR was generated by the agentic build system.*
"""
    
    result = subprocess.run(
        ["gh", "pr", "create", "--title", title, "--body", body, "--base", "master"],
        cwd=safe_dir,
        capture_output=True,
        text=True
    )
    
    if result.returncode != 0:
        log("ERROR", f"PR creation failed: {result.stderr}")
        return None
    
    # Extract PR URL from output
    pr_url = result.stdout.strip()
    return pr_url


def write_results(bundle_dir: Path, branch: str, commit: str, rebuild_success: bool,
                  pr_url: str | None):
    """Write results back to bundle."""
    analysis_dir = bundle_dir / "analysis"
    analysis_dir.mkdir(exist_ok=True)
    
    (analysis_dir / "branch.txt").write_text(branch + "\n")
    (analysis_dir / "commit.txt").write_text(commit + "\n")
    (analysis_dir / "rebuild_status.txt").write_text(
        "SUCCESS" if rebuild_success else "FAILED"
    )
    
    if pr_url:
        (analysis_dir / "pr_url.txt").write_text(pr_url + "\n")


def main():
    parser = argparse.ArgumentParser(
        description="Apply AI-generated patches, rebuild, and open PR"
    )
    parser.add_argument("--bundle", help="Path to evidence bundle")
    parser.add_argument("--dry-run", action="store_true", help="Show what would be done")
    parser.add_argument("--no-rebuild", action="store_true", help="Skip rebuild")
    parser.add_argument("--no-push", action="store_true", help="Skip git push (local testing)")
    parser.add_argument("--no-pr", action="store_true", help="Skip PR creation")
    args = parser.parse_args()
    
    # Get bundle directory
    bundle_dir = Path(args.bundle) if args.bundle else Path(os.environ.get("BUNDLE_DIR", ""))
    if not bundle_dir or not bundle_dir.exists():
        log("ERROR", f"Bundle directory not found: {bundle_dir}")
        sys.exit(1)
    
    # Check required files
    patch_path = bundle_dir / "analysis" / "patch.diff"
    if not patch_path.exists():
        log("ERROR", f"patch.diff not found in {bundle_dir}/analysis/")
        sys.exit(1)
    
    # Get configuration
    safe_dir = Path(os.environ.get("SAFE_DELTAPORTS_DIR", str(DEFAULT_SAFE_CLONE)))
    ssh_key = Path(os.environ.get("VM_SSH_KEY", str(DEFAULT_SSH_KEY)))
    ssh_port = os.environ.get("VM_SSH_PORT", DEFAULT_SSH_PORT)
    ssh_host = os.environ.get("VM_SSH_HOST", DEFAULT_SSH_HOST)
    
    log("INFO", f"Bundle: {bundle_dir}")
    log("INFO", f"Safe clone: {safe_dir}")
    log("INFO", f"Dry run: {args.dry_run}")
    log("INFO", f"Platform: {'DragonFlyBSD (local)' if IS_DRAGONFLY else 'Linux (SSH to VM)'}")
    
    # Parse metadata
    meta = parse_meta(bundle_dir)
    origin = meta.get("origin", "")
    if not origin:
        log("ERROR", "No origin found in meta.txt")
        sys.exit(1)
    
    triage = parse_triage(bundle_dir)
    classification = triage.get("classification", "unknown")
    confidence = triage.get("confidence", "unknown")
    root_cause = triage.get("root_cause", "")
    
    log("INFO", f"Origin: {origin}")
    log("INFO", f"Classification: {classification}, Confidence: {confidence}")
    
    # Generate branch name
    branch = generate_branch_name(origin, classification)
    log("INFO", f"Branch: {branch}")
    
    # Step 1: Ensure safe clone
    if not ensure_safe_clone(safe_dir, args.dry_run):
        sys.exit(1)
    
    # Step 2: Apply patch and commit
    success, commit_sha = apply_patch_to_clone(
        safe_dir, patch_path, branch, origin, 
        classification, bundle_dir, args.dry_run
    )
    if not success:
        log("ERROR", "Failed to apply patch")
        sys.exit(1)
    log("INFO", f"Commit: {commit_sha}")
    
    # Step 3: Push branch (skip if --no-push)
    if args.no_push:
        log("INFO", "Skipping push (--no-push)")
    elif not push_branch(safe_dir, branch, args.dry_run):
        log("ERROR", "Failed to push branch")
        sys.exit(1)
    
    # Step 4: Fetch and sync (platform-aware)
    # In --no-push mode on DragonFly, we sync directly from safe_dir
    rebuild_success = False
    if not args.no_rebuild:
        if IS_DRAGONFLY:
            if args.no_push:
                # Local mode without push: sync directly from safe clone
                fetch_success = local_sync_from_safe_clone(origin, safe_dir, args.dry_run)
            else:
                # Local mode: fetch branch and sync locally
                fetch_success = local_fetch_and_sync(origin, branch, safe_dir, args.dry_run)
        else:
            # SSH mode: fetch branch on VM and sync
            fetch_success = vm_fetch_and_sync(origin, branch, ssh_host, ssh_port, ssh_key, args.dry_run)
        
        if not fetch_success:
            log("ERROR", "Failed to fetch/sync")
            # Continue to write results, but mark as failed
        else:
            # Step 5: Rebuild (platform-aware)
            if IS_DRAGONFLY:
                rebuild_success, log_excerpt = local_rebuild(origin, args.dry_run)
            else:
                rebuild_success, log_excerpt = vm_rebuild(
                    origin, ssh_host, ssh_port, ssh_key, args.dry_run
                )
            
            if rebuild_success:
                log("INFO", "Rebuild SUCCEEDED!")
            else:
                log("WARN", f"Rebuild FAILED. Log excerpt:\n{log_excerpt}")
    else:
        log("INFO", "Skipping rebuild (--no-rebuild)")
        rebuild_success = True  # Assume success for PR
    
    # Step 6: Create PR (only if rebuild succeeded)
    pr_url = None
    if not args.no_pr and rebuild_success:
        pr_url = create_pr(
            safe_dir, branch, origin, classification,
            confidence, root_cause, bundle_dir, args.dry_run
        )
        if pr_url:
            log("INFO", f"PR created: {pr_url}")
        else:
            log("WARN", "Failed to create PR")
    elif not rebuild_success:
        log("INFO", "Skipping PR (rebuild failed)")
    else:
        log("INFO", "Skipping PR (--no-pr)")
    
    # Write results to bundle
    write_results(bundle_dir, branch, commit_sha, rebuild_success, pr_url)
    
    log("INFO", "Done!")
    
    if pr_url:
        print(f"\nPR URL: {pr_url}")
    
    sys.exit(0 if rebuild_success else 1)


if __name__ == "__main__":
    main()
